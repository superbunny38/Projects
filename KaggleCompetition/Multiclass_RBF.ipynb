{"cells":[{"cell_type":"code","execution_count":null,"id":"c1ad2927","metadata":{"id":"c1ad2927"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import math\n","import random\n","from tqdm.auto import tqdm\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"944c8eb3","metadata":{"id":"944c8eb3","outputId":"bebc456b-04c3-4f6c-8554-02ce5050211b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>traffic(t-10)</th>\n","      <th>traffic(t-9)</th>\n","      <th>traffic(t-8)</th>\n","      <th>traffic(t-7)</th>\n","      <th>traffic(t-6)</th>\n","      <th>traffic(t-5)</th>\n","      <th>traffic(t-4)</th>\n","      <th>traffic(t-3)</th>\n","      <th>traffic(t-2)</th>\n","      <th>traffic(t-1)</th>\n","      <th>traffic(t)</th>\n","      <th>type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>3.0</td>\n","      <td>12.0</td>\n","      <td>6.0</td>\n","      <td>6.0</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>17.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   traffic(t-10)  traffic(t-9)  traffic(t-8)  traffic(t-7)  traffic(t-6)  \\\n","0            3.0           2.0           5.0           6.0           6.0   \n","1            2.0           5.0           6.0           6.0           4.0   \n","2            5.0           6.0           6.0           4.0           6.0   \n","3            6.0           6.0           4.0           6.0           6.0   \n","4            6.0           4.0           6.0           6.0           3.0   \n","\n","   traffic(t-5)  traffic(t-4)  traffic(t-3)  traffic(t-2)  traffic(t-1)  \\\n","0           4.0           6.0           6.0           3.0          12.0   \n","1           6.0           6.0           3.0          12.0           6.0   \n","2           6.0           3.0          12.0           6.0           6.0   \n","3           3.0          12.0           6.0           6.0           4.0   \n","4          12.0           6.0           6.0           4.0           6.0   \n","\n","   traffic(t)  type  \n","0         6.0     0  \n","1         6.0     0  \n","2         4.0     0  \n","3         6.0     0  \n","4        17.0     0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_csv(\"./data/train.csv\")\n","train_df.head()"]},{"cell_type":"markdown","id":"a53a8c1e","metadata":{"id":"a53a8c1e"},"source":["# Split and scale train data into stratified 5 folds"]},{"cell_type":"code","execution_count":null,"id":"d431573b","metadata":{"id":"d431573b"},"outputs":[],"source":["X,y = train_df.drop('type',axis = 1).to_numpy(),train_df['type']"]},{"cell_type":"code","execution_count":null,"id":"fb4e3468","metadata":{"id":"fb4e3468"},"outputs":[],"source":["X_scaled = (X-X.mean())/X.std()"]},{"cell_type":"code","execution_count":null,"id":"a21b87fe","metadata":{"id":"a21b87fe","outputId":"c8364c34-b53a-43cd-ff59-b1f81881caf0"},"outputs":[{"data":{"text/plain":["5"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import StratifiedKFold\n","skf = StratifiedKFold(n_splits=5,random_state=38,shuffle = True)\n","skf.get_n_splits(X_scaled, y)"]},{"cell_type":"code","execution_count":null,"id":"99f230c8","metadata":{"id":"99f230c8"},"outputs":[],"source":["global fold_dict\n","fold_dict = dict()\n","\n","for i, (train_index, test_index) in enumerate(skf.split(X_scaled,y)):\n","    fold_dict[f'fold{i}'] = {'train_indices':train_index, 'test_indices':test_index}"]},{"cell_type":"code","execution_count":null,"id":"26f212c3","metadata":{"id":"26f212c3","outputId":"cb552263-5bf9-4fc4-b66f-6b35ea01a4d6"},"outputs":[{"data":{"text/plain":["dict_keys(['fold0', 'fold1', 'fold2', 'fold3', 'fold4'])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["fold_dict.keys()"]},{"cell_type":"code","execution_count":null,"id":"95e06583","metadata":{"scrolled":true,"id":"95e06583","outputId":"bd0f08b6-4a65-4e8a-e56a-1faef3ecdddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Counter({0: 1578, 1: 588, 2: 182, 3: 181})\n","Counter({0: 1577, 1: 589, 2: 182, 3: 181})\n","Counter({0: 1577, 1: 589, 3: 182, 2: 181})\n","Counter({0: 1577, 1: 589, 3: 182, 2: 181})\n","Counter({0: 1577, 1: 588, 2: 182, 3: 182})\n"]}],"source":["from collections import Counter\n","print(Counter(y[fold_dict['fold0']['test_indices']]))\n","print(Counter(y[fold_dict['fold1']['test_indices']]))\n","print(Counter(y[fold_dict['fold2']['test_indices']]))\n","print(Counter(y[fold_dict['fold3']['test_indices']]))\n","print(Counter(y[fold_dict['fold4']['test_indices']]))"]},{"cell_type":"markdown","id":"b47eb3ba","metadata":{"id":"b47eb3ba"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"id":"4264ba93","metadata":{"id":"4264ba93"},"outputs":[],"source":["import numpy as np\n","\n","class rbfSVMClassifier:\n","    def __init__(self,n_iters=5, lr = 0.0001, random_seed=3, sigma=1):\n","        self.n_iters = n_iters # 몇 회 반복하여 적절한 값을 찾을지 정하는 파라미터\n","        self.lr = lr  # 학습률과 관련된 파라미터 \n","        self.sigma = sigma\n","        self.random_seed = random_seed\n","        np.random.seed(self.random_seed)\n","\n","    def rbf_kernel(self,x,z):\n","        numer = -(x-z).dot(x-z)\n","        denom = 2*self.sigma**2\n","        return math.exp(numer/denom) \n","    \n","    def sign(self,scalar):\n","        if scalar >= 0:\n","            return 1\n","        else:\n","            return 0\n","    \n","    def update_weight(self,x_i,y_i,i):\n","        summ = 0\n","        if i == 0:\n","            b_next = self.lr*(y_i-self.sign(0))\n","            self.weight = np.append(self.weight,b_next)\n","            return self.weight\n","        else:\n","            for j in range(i):\n","                summ += self.weight[j]*self.rbf_kernel(self.train_x[j],x_i)\n","            b_next = self.lr*(y_i-self.sign(summ))\n","            self.weight =np.append(self.weight,b_next)\n","            return self.weight\n","    \n","    def fit(self, x_, y_orig):\n","        \"\"\"\n","        본 함수는 x, y를 활용하여 훈련하는 과정을 코딩하는 부분입니다.\n","        아래 reference 사이트의 gradient 계산 부분을 참고하세요.\n","        reference: https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n","        아래 총 6개의 None 부분을 채우시면 됩니다.\n","\n","        \"\"\"\n","        n_samples, n_features = x_.shape\n","        # hint: y값을 SVM 계산에 활용해주기 위하여 0에 해당하는 y값들을 -1로 변환\n","        y_ =  np.array(y_orig)#numpy array의 y를 y_에 담아줍니다       \n","        y_[y_ == 0] = -1#0에 해당하는 y_값들을 -1로 변환합니다.\n","        \n","        self.weight = np.array([])\n","        \n","        n_label = np.sum((y_==1)*1)\n","        \n","        for _ in tqdm(range(self.n_iters),leave =False, colour = \"cyan\", desc = f\"training for {self.n_iters} iterations\"):\n","            \n","            ###### Oversampling #######\n","            non_label_indices = np.where(y_ == -1)[0]\n","            label_indices = np.where(y_ != -1)[0]\n","            more_sample_n = len(non_label_indices)-len(label_indices)\n","            n_iter = _\n","            if more_sample_n <0:\n","                more_sample_indices = np.random.choice(non_label_indices,size = -more_sample_n,replace = False)\n","            else:\n","                more_sample_indices = np.random.choice(label_indices,size = more_sample_n,replace = True)\n","            x = np.vstack([x_,x_[more_sample_indices,:]])\n","            y = np.concatenate([y_,y_[more_sample_indices]])\n","            self.train_x = x\n","            self.train_y = y \n","            n_samples_oversampled = len(y)\n","            assert Counter(y)[list(Counter(y).keys())[0]] == Counter(y)[list(Counter(y).keys())[1]]\n","            assert x.shape[0] == y.shape[0]\n","            for i in tqdm(range(n_samples_oversampled),leave = False,colour = \"green\",desc = \"updating through all train data\"):\n","                x_i = x[i]\n","                y_i = y[i]\n","                #### Update considering gradient\n","                self.weight = self.update_weight(x_i,y_i,i)\n","                \n","        return self.weight\n","    \n","    def predict_(self,x):#predict for single instance\n","        summ = 0\n","        for idx, x_ in enumerate(self.train_x):\n","            summ += self.weight[idx]*self.rbf_kernel(x,x_)\n","        return self.sign(summ)\n","    \n","    def predict(self, x):\n","        n_test_data = x.shape[0]\n","        preds = []\n","        for i in range(n_test_data):\n","            pred = self.predict_(x[i,:])\n","            preds.append(pred)\n","        preds = np.array(preds)\n","        return preds#예측 값을 담은 배열인 approx를 반환합니다\n","    \n","    def sigmoid(self,z):\n","        return 1./(1.+np.exp(-z))\n","    \n","    def get_prob_(self,x_i):\n","        summ = 0\n","        for idx, x_ in enumerte(self.train_x):\n","            summ += self.weight[idx]*self.rbf_kernel(x_i,x_)\n","        return self.sigmoid(summ)\n","    \n","    def get_prob(self,X):\n","        n_test_data = x.shape[0]\n","        probs = []\n","        for i in range(n_test_data):\n","            prob = self.get_prob_(x[i,:])\n","            probs.append(prob)\n","        probs = np.array(probs)\n","        return probs\n","\n","\n","    def get_accuracy(self, y_true, y_pred):\n","        \"\"\"\n","            y_true, y_pred가 들어왔을 때, 정확도를 계산하는 함수.\n","            sklearn의 accuracy_score 사용 불가능 / sklearn의 accuracy_score 함수를 구현한다고 생각하면 됩니다.\n","            넘파이만을 활용하여 정확도 계산 함수를 작성하세요.\n","        \"\"\"\n","        acc = np.sum(y_true == y_pred)/len(y_pred)#예측하고자 하는 전체 데이터 수 개수(len(y_pred)) 중 예측 값과 실제 값이 일치하는 데이터 개수(np.sum(y_true == y_pred))의 비율로 정확도를 계산합니다\n","        return acc #정확도를 담은 acc를 반환합니다\n","\n","\n","class MultiClassSVM:\n","    def __init__(self, kernel='rbf', C=1, gamma=0.1, n_iters = 3):\n","        self.kernel = kernel\n","        self.C = C\n","        self.gamma = gamma\n","        self.svms = []\n","        self.n_iters = n_iters\n","        self.n_classes = 4\n","\n","    def fit(self, X, y):\n","        self.svms = []\n","        n_classes = self.n_classes\n","        for i in tqdm(range(n_classes),leave = False, colour=\"pink\",desc = \"exploring all classes..\"):\n","            y_temp = np.where(y == i, 1, -1)\n","            svm = rbfSVMClassifier(lr=self.C, sigma=self.gamma, n_iters = self.n_iters)\n","            svm.fit(X, y_temp)\n","            self.svms.append(svm)\n","            \n","        assert len(self.svms) == self.n_classes\n","    def predict(self, X):\n","        predictions = np.zeros((X.shape[0], self.n_classes))\n","        for i, svm in enumerate(self.svms):\n","            predictions[:, i] = svm.predict(X)\n","        return np.argmax(predictions, axis=1)"]},{"cell_type":"markdown","id":"3308bd29","metadata":{"id":"3308bd29"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"id":"96451661","metadata":{"id":"96451661"},"outputs":[],"source":["from collections import Counter\n","def train_test_binary_model(model,label):\n","    avg_train_acc = []\n","    avg_test_acc = []\n","    for fold in tqdm(fold_dict.values(),leave=False,desc = \"5 folds...\"):\n","        train_X,train_y = X_scaled[fold['train_indices']],y[fold['train_indices']]\n","        test_X,test_y = X_scaled[fold['test_indices']],y[fold['test_indices']]\n","        use_train_y,use_test_y = train_y,test_y\n","        model.fit(train_X,use_train_y)\n","        train_preds = model.predict(train_X)\n","        print(\"predicted train dist:\",Counter(train_preds))\n","        assert train_preds.shape[0] == np.sum(list(Counter(train_preds).values()))\n","        train_acc = np.mean(train_preds == use_train_y)\n","        test_preds = model.predict(test_X)\n","        print(\"predicted test dist:\",Counter(test_preds))\n","        test_acc = np.mean(test_preds == use_test_y)\n","        \n","        if test_acc < 0.85:\n","            print(\"skipping 5 folds training because acc too low!\")\n","            print(f\"test_acc: {test_acc}\")\n","            return 0.,0.\n","        avg_train_acc.append(train_acc)\n","        avg_test_acc.append(test_acc)\n","        \n","    return np.mean(np.array(avg_train_acc)),np.mean(np.array(avg_test_acc))"]},{"cell_type":"code","execution_count":null,"id":"b523a0fc","metadata":{"scrolled":true,"id":"b523a0fc"},"outputs":[],"source":["import copy\n","save_models = dict()\n","\n","\n","C = [0.001,0.01,0.1,1.,5.]\n","gammas = [0.01,0.1,1.0]\n","best_param0 = dict()\n","best_acc_0 = 0\n","best_train_acc = 0\n","\n","for C_ in C:\n","    for gamma in gammas:\n","        svm0 = MulticlassSVM(C=C_,gamma = gamma,n_iters=2)\n","        train_acc,test_acc = train_test_binary_model(svm0,0)\n","        print(f\"(C:{C_} gamma:{gamma}) acc: {round(train_acc,4)} val acc:{round(test_acc,3)}\")\n","        if train_acc > best_train_acc and test_acc>=best_acc_0:\n","            print(\">>best model updated\\n\")\n","            best_acc_0 = test_acc\n","            best_param0['C']=C_\n","            best_param0['gamma'] = gamma\n","            best_svm0 = copy.deepcopy(svm0)\n","            best_train_acc = train_acc\n","            save_name = f\"./weights/rbf_multiclass{str(best_acc_0)[:4]}.pt\"\n","            best_param0['train_acc'] = best_train_acc\n","            best_param0['test_acc'] = best_acc_0\n","            best_param0['best_model'] = best_svm0\n","            torch.save(best_param0,save_name)\n","        if test_acc > 0.85:\n","            save_models[test_acc] = {'train_acc':train_acc,'model':copy.deepcopy(svm0)}"]},{"cell_type":"code","execution_count":null,"id":"8363a196","metadata":{"id":"8363a196"},"outputs":[],"source":["print(\"best_train_acc:\",best_train_acc,\"best test acc:\",best_acc_0)\n","best_param0"]},{"cell_type":"code","execution_count":null,"id":"82ab44d2","metadata":{"id":"82ab44d2"},"outputs":[],"source":["save_name = f\"./weights/oversampling_label0_{str(best_acc_0)[:4]}.pt\"\n","best_param0['train_acc'] = best_train_acc\n","best_param0['test_acc'] = best_acc_0\n","best_param0['best_model'] = best_svm0\n","torch.save(best_param0,save_name)"]},{"cell_type":"code","execution_count":null,"id":"c815469f","metadata":{"id":"c815469f"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}